# ğŸ­ Facial Emotion Recognition using Deep Learning  



## ğŸš€ Project Overview  
This project aims to classify human facial expressions into different emotions using **Deep Learning**. A **Convolutional Neural Network (CNN)** is trained to recognize emotions from facial images and can be deployed for **real-time facial emotion detection** using a webcam.  

ğŸ”¹ **Emotions Detected:**  
âœ… Happy ğŸ˜Š  
âœ… Sad ğŸ˜”  
âœ… Angry ğŸ˜¡  
âœ… Neutral ğŸ˜  
âœ… Surprised ğŸ˜²  
âœ… Fearful ğŸ˜¨  

ğŸ”¹ **Key Features:**  
âœ”ï¸ **Deep Learning-based Emotion Recognition** using **CNN & Transfer Learning** (VGG16, ResNet50V2)  
âœ”ï¸ **Real-time Emotion Detection App** using **OpenCV** & **Flask**  
âœ”ï¸ **Preprocessing & Augmentation** for improved model accuracy  
âœ”ï¸ **Performance Evaluation** using Accuracy, Precision, Recall & Confusion Matrix  

---

1ï¸âƒ£ Importing Required Libraries

a. The first step involves importing necessary Python libraries:

b. TensorFlow & Keras: Used for building and training the deep learning model.

c. OpenCV: Helps in real-time face detection.

d. Matplotlib & Seaborn: Used for visualizing data and model performance.

e. Sklearn: Provides functions for data preprocessing, evaluation, and splitting datasets.


2ï¸âƒ£ Loading and Preprocessing the Dataset

a. The dataset consists of facial images labeled with different emotions.

b. Images are converted to grayscale to reduce complexity.

c. They are resized to a fixed dimension (e.g., 48x48 pixels) for uniformity.

d. Data augmentation techniques (rotation, flipping, zooming) are applied to increase dataset size and model generalization.


3ï¸âƒ£ Splitting Data into Training and Testing Sets

a. The dataset is divided into training and testing sets (e.g., 80% train, 20% test).

b. Labels are one-hot encoded so that the model can classify emotions correctly.


4ï¸âƒ£ Building the Deep Learning Model

 A Convolutional Neural Network (CNN) is used to extract features from facial images.
 The architecture consists of:
 
 a. Convolutional Layers: Detects facial features like eyes, mouth, and expressions.
 
 b. MaxPooling Layers: Reduces spatial dimensions while retaining important features.

 c. Fully Connected Layers: Helps in final classification.
 
 d. Activation functions like ReLU and Softmax are used for non-linearity and classification.
 
 e. Batch Normalization and Dropout are added to prevent overfitting.
 

5ï¸âƒ£ Training the Model
The model is compiled using:
a. Loss Function: Categorical Crossentropy (as itâ€™s a multi-class classification problem).

b. Optimizer: Adam (efficient learning rate adaptation).

c. Metrics: Accuracy to track model performance.

d. Training is performed using the dataset, with validation on test data.

e. The modelâ€™s accuracy and loss curves are plotted to analyze learning behavior.


6ï¸âƒ£ Model Evaluation
The model is tested on unseen images to check accuracy.

A confusion matrix is plotted to observe misclassifications.

Performance metrics like Precision, Recall, and F1-score are computed.

7ï¸âƒ£ Real-time Facial Emotion Recognition App
A Flask-based web app is created to detect emotions using a webcam.

OpenCV is used to capture real-time video frames.

The model predicts emotions and overlays the detected emotion on the screen.

The app can be accessed via a web browser, allowing users to test real-time emotion recognition.


ğŸ”® Future Improvements
ğŸš€ Improve accuracy by using a larger and more diverse dataset.
ğŸš€ Deploy on edge devices for real-time, low-latency applications.
ğŸš€ Integrate with AI assistants to create emotion-aware applications.


ğŸ“œ Conclusion
This project demonstrates how deep learning and computer vision can be used to detect human emotions in real-time. It has applications in healthcare, security, human-computer interaction, and AI-based customer support systems.

ğŸ’¡ Want to contribute? Feel free to fork, experiment, and improve the model!

ğŸ‘¨â€ğŸ’» Author
Abhishek Yadav
ğŸš€ Passionate about Machine Learning & AI

ğŸ“Œ Connect with me:
ğŸ”— GitHub
ğŸ”— LinkedIn
ğŸ”— Portfolio
